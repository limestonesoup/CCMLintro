{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ef9f706",
   "metadata": {},
   "source": [
    "Level 1 and Level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "48bb325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#first I just built the API connection to Mistral, \n",
    "#so that I know that it works\n",
    "apiKey = \"fbEJEobe12xbsYUEUtXAo1VZ9LBGqFjz\"\n",
    "#this was renamed to askMistralNode with state as input l8r\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "MEMORY_PATH = \"memory.json\"\n",
    "# so very basic memory system, just a json file\n",
    "#that stores as many messages as you want\n",
    "def loadMemory():\n",
    "    if not os.path.exists(MEMORY_PATH):\n",
    "        return {\"messages\": [], \"counter\": 0, \"persona\": \"\"}\n",
    "    with open(MEMORY_PATH, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def saveMemory(data):\n",
    "    with open(MEMORY_PATH, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "        \n",
    "        \n",
    "def askMistralNode(state):\n",
    "    memory = loadMemory()\n",
    "    msg = state[\"input\"]\n",
    "    \n",
    "    memory[\"messages\"].append(msg)\n",
    "    memory[\"messages\"] = memory[\"messages\"][-12:]  \n",
    "    memory[\"counter\"] += 1\n",
    "    \n",
    "    context = \"\\n\".join(memory[\"messages\"][-3:])\n",
    "    \n",
    "    if memory[\"counter\"] % 6 == 0:\n",
    "        chPrompt = (\n",
    "            \"These are recent user prompts. Summarize the user's interests or personality \"\n",
    "            \"as an assistant might find useful to tailor future replies. Dive into the summary directly.:\\n\" +\n",
    "            \"\\n\".join(memory[\"messages\"][-6:-1])\n",
    "        )\n",
    "        res = requests.post(\n",
    "            \"https://api.mistral.ai/v1/chat/completions\",\n",
    "            headers={\n",
    "                \"Authorization\": f\"Bearer {apiKey}\",\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            },\n",
    "            json={\n",
    "                \"model\": \"mistral-medium\",\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You summarize users from their chat logs.\"},\n",
    "                    {\"role\": \"user\", \"content\": chPrompt}\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        persona = res.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        memory[\"persona\"] = persona\n",
    "    \n",
    "    saveMemory(memory)\n",
    "\n",
    "    totPrompt = (\n",
    "        f\"[You know the following about the user: {memory.get('persona', '').strip()}]\\n\"\n",
    "        f\"[Recent context: {context}]\\n\"\n",
    "        f\"{msg}\"\n",
    "    )\n",
    "\n",
    "    res = requests.post(\n",
    "        \"https://api.mistral.ai/v1/chat/completions\",\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {apiKey}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        },\n",
    "        json={\n",
    "            \"model\": \"mistral-medium\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that analyzes user requests. If the user is asking for a weather forecast, reply with 'weather' on the first line, followed by the precise location (city/district/place, prefecture/province/county). If the user is asking for a mathematical calculation, reply with 'calc' on the first line. If the user is asking for fashion trends, reply with 'fashion' on the first line, followed by the precise location (city/district/place, prefecture/province/sector). For all other requests, reply with 'llm' on the first line and then respond normally.\"},\n",
    "                {\"role\": \"user\", \"content\": totPrompt}\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    reply = res.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    lines = reply.strip().split(\"\\n\")\n",
    "    task = lines[0].strip().lower()\n",
    "    loc = \"\"\n",
    "    for i in range(1, len(lines)):\n",
    "        loc += lines[i].strip() + \", \"\n",
    "    loc = loc[:-2] if (task == \"weather\" or task == \"fashion\") and len(lines) > 1 else None\n",
    "    \n",
    "    return {\"output\": reply, \"task\": task, \"location\": loc, \"input\": msg}\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import re\n",
    "\n",
    "def decide(state):\n",
    "    return state.get(\"task\", \"llm\")\n",
    "#so the router  returns llm by default if no agentic pathway called\n",
    "\n",
    "def doMathNode(state):\n",
    "    \"do maffs\"\n",
    "    input = state[\"input\"]\n",
    "    maffs = re.split(r'[a-zA-Z!?,\":;_]+', input)\n",
    "    maffs = [m.strip() for m in maffs if m.strip()]\n",
    "    soln = \"\"\n",
    "    \n",
    "    if maffs:\n",
    "        i = 1\n",
    "        for s in maffs:\n",
    "            if re.match(r'^[\\d\\.\\+\\-\\*/\\(\\)\\s]+$', s):\n",
    "                try:\n",
    "                    result = eval(s)\n",
    "                    soln += (f\"{i}th expression is {result}\\n\")\n",
    "                    i += 1\n",
    "                except Exception as e:\n",
    "                    soln += (f\"Math Error in '{s}': {str(e)}\\n\")\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        if i == 1:\n",
    "            return {\"output\": \"no math found\", \"input\": input}\n",
    "        return {\"output\": \"math processing completed.\\n\" + soln, \"input\": input}\n",
    "    else:\n",
    "        return {\"output\": \"no math found\", \"input\": input}\n",
    "\n",
    "graph = StateGraph(dict)\n",
    "\n",
    "graph.add_node(\"llm\", askMistralNode)\n",
    "graph.add_edge(START, \"llm\")\n",
    "#so we start at askMistralNode, and then we go to the decision node\n",
    "#but router node is kind of a dummy == node, just because in askMistralNode\n",
    "#we have the ACTUAL functionality of calling the AI (n so we dont call AI twice)\n",
    "#more of graph explained next cell\n",
    "graph.add_edge(\"llm\", \"router\")\n",
    "graph.add_node(\"calc\", doMathNode)\n",
    "graph.add_edge(\"calc\", END)\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160dc050",
   "metadata": {},
   "source": [
    "Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d7fc6336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x19f80e8ae10>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import quote\n",
    "#hey i just learned urllib.parse.quote is a thing\n",
    "def getWeather(state):\n",
    "    loc = state.get(\"location\")\n",
    "    if not loc:\n",
    "        return {\"output\": \"No location found.\", \"input\": state[\"input\"]}\n",
    "    #so one of the earlier things i tried was opencage ai (because locations can be like LAX or London, ohio\n",
    "    # or the Bronx or whatever (so we DO need a geocoder for better fidelity)\n",
    "    # but opencage was not working for ONLY Asian/African/East Europe so locationiq it is)\n",
    "    print(loc)\n",
    "    geo = requests.get(f\"https://eu1.locationiq.com/v1/search?key=pk.22b59a75499c47d8801ed033a5d1dab0&q={quote(loc)}&format=json\")\n",
    "    # if geo.status_code != 200:\n",
    "    #     return {\"output\": \"Geo lookup failed\", \"input\": state[\"input\"]}\n",
    "    \n",
    "    try:\n",
    "        res = geo.json()[0]\n",
    "        lat = float(res[\"lat\"])\n",
    "        lng = float(res[\"lon\"])\n",
    "    except Exception as e:\n",
    "        return {\"output\": f\"Geocoding error: {e}\", \"input\": state[\"input\"]}\n",
    "    \n",
    "    url = f\"http://api.weatherapi.com/v1/forecast.json?key=7bdb0a1fd8ba433c98061921252105&q={lat},{lng}&days=10\"\n",
    "    #Im using weatherapis forecast API which is very neat in its data and allowed me to make sexy graphs\n",
    "    try:\n",
    "        weather = requests.get(url)\n",
    "        if weather.status_code == 200:\n",
    "            weatherData = weather.json()\n",
    "            summary = processWeatherData(weatherData)\n",
    "            return {\"output\": summary, \"weatherData\": weatherData, \"input\": state[\"input\"]}\n",
    "        return {\"output\": f\"Weather error {weather.status_code}\", \"input\": state[\"input\"]}\n",
    "    except Exception as e:\n",
    "        return {\"output\": f\"Exception: {e}\", \"input\": state[\"input\"]}\n",
    "\n",
    "\n",
    "def dmsToDecimal(dms):\n",
    "    d, m, s = map(float, re.findall(r'(\\d+\\.?\\d*)', dms))\n",
    "    return round(d + m / 60 + s / 3600, 6)\n",
    "\n",
    "graph.add_node(\"weather\", getWeather)\n",
    "graph.add_node(\"router\", lambda x: x)\n",
    "\n",
    "graph.add_edge(\"weather\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d8b05248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "def getFashion(state):\n",
    "    loc = state.get(\"location\")\n",
    "    if not loc:\n",
    "        return {\"output\": \"No location found.\", \"input\": state[\"input\"]}\n",
    "\n",
    "    q = f\"current fashion trends {loc.split(',')[0]}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
    "\n",
    "    try:\n",
    "        url = f\"https://www.google.com/search?q={quote(q)}\"\n",
    "        r = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        \n",
    "        srs = [\n",
    "            \"div[data-attrid='wa:/description']\",\n",
    "            \"div[data-attrid='kc:/fashion/fashion:short description']\",\n",
    "            \"div[data-sncf]\"\n",
    "        ]\n",
    "        overview = \"No overview found.\"\n",
    "        for s in srs:\n",
    "            divs = soup.select(s)\n",
    "            if divs:\n",
    "                overview = divs[0].get_text().strip()\n",
    "                break\n",
    "    except Exception as e:\n",
    "        overview = f\"Overview error: {e}\"\n",
    "\n",
    "    try:\n",
    "        imgUrl = f\"https://www.google.com/search?q={quote(q)}&tbm=isch&tbs=qdr:w\"\n",
    "        r = requests.get(imgUrl, headers=headers)\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        imgLinks = [img.get(\"src\") for img in soup.select(\"img\") \n",
    "                   if img.get(\"src\") and \"http\" in img.get(\"src\")][:10]\n",
    "    except Exception as e:\n",
    "        imgLinks = [f\"Image error: {e}\"]\n",
    "\n",
    "    return {\"output\": overview, \"images\": imgLinks, \"input\": state[\"input\"]}\n",
    "\n",
    "\n",
    "graph.add_node(\"fashion\", getFashion)\n",
    "\n",
    "graph.add_conditional_edges(\"router\", decide, {\n",
    "    \"weather\": \"weather\", \n",
    "    \"calc\": \"calc\", \n",
    "    \"fashion\": \"fashion\",\n",
    "    \"llm\": END\n",
    "})\n",
    "#this is the ^^^ heart of the graph. delete this for fun stuff.\n",
    "graph.add_edge(\"fashion\", END)\n",
    "weatherMind = graph.compile()\n",
    "\n",
    "# weatherMind.get_graph().draw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28add7b3",
   "metadata": {},
   "source": [
    "Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b1162c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def processWeatherData(weatherData):\n",
    "    location = weatherData.get(\"location\", {})\n",
    "    name = location.get(\"name\", \"Unknown\")\n",
    "    region = location.get(\"region\", \"Unknown\")\n",
    "    country = location.get(\"country\", \"Unknown\")\n",
    "    localtime = location.get(\"localtime\", \"Unknown\")\n",
    "\n",
    "    summary = f\"\\n=== Weather Forecast from Station at {name}, {region}, {country} ===\\n\"\n",
    "    summary += f\"Local Time: {localtime}\\n\"\n",
    "    \n",
    "    forecastDays = weatherData.get(\"forecast\", {}).get(\"forecastday\", [])\n",
    "    for day in forecastDays:\n",
    "        date = day[\"date\"]\n",
    "        maxTemp = day[\"day\"][\"maxtemp_c\"]\n",
    "        minTemp = day[\"day\"][\"mintemp_c\"]\n",
    "        avgTemp = day[\"day\"][\"avgtemp_c\"]\n",
    "        avgTempF = day[\"day\"][\"avgtemp_f\"]\n",
    "        maxWind = day[\"day\"][\"maxwind_kph\"]\n",
    "        maxWindM = day[\"day\"][\"maxwind_mph\"]\n",
    "        totalPrecip = day[\"day\"][\"totalprecip_mm\"]\n",
    "        totalPrecipI = day[\"day\"][\"totalprecip_in\"]\n",
    "        snow = day[\"day\"].get(\"totalsnow_cm\", 0)\n",
    "        snowI = day[\"day\"].get(\"totalsnow_in\", 0)\n",
    "        condition = day[\"day\"][\"condition\"][\"text\"]\n",
    "        chanceRain = day[\"day\"].get(\"daily_chance_of_rain\", \"N/A\")\n",
    "        chanceSnow = day[\"day\"].get(\"daily_chance_of_snow\", \"N/A\")\n",
    "\n",
    "        summary += f\"\\n### {date} - {condition}\\n\" + \\\n",
    "        f\"Temp: {avgTemp}°C (avg) [{avgTempF}°F], {maxTemp}°C/{minTemp}°C (high/low)\\n\" + \\\n",
    "        f\"Wind: {maxWind} kph [{maxWindM} mph]\\n\" + \\\n",
    "        f\"Precipitation: {totalPrecip} mm [{totalPrecipI} in]\\n\" + \\\n",
    "        f\"Snow: {snow} cm [{snowI} in]\\n\" + \\\n",
    "        f\"Chance of Rain: {chanceRain}%\\n\" + \\\n",
    "        f\"Chance of Snow: {chanceSnow}%\\n\"\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def plotWeatherGraphs(weatherData):\n",
    "    hours = []\n",
    "    hour_labels = []\n",
    "    tempC = []\n",
    "    feelslikeC = []\n",
    "    windKph = []\n",
    "    gustKph = []\n",
    "    precipMm = []\n",
    "    snowCm = []\n",
    "    humidity = []\n",
    "    cloud = []\n",
    "    windchillC = []\n",
    "    heatindexC = []\n",
    "    dewpointC = []\n",
    "    rainChance = []\n",
    "    snowChance = []\n",
    "    visibilityKm = []\n",
    "    uvIndex = []\n",
    "\n",
    "    dayends = [i * 24 for i in range(10)]\n",
    "\n",
    "    for day in weatherData[\"forecast\"][\"forecastday\"]:\n",
    "        for hour in day[\"hour\"]:\n",
    "            \n",
    "            hour_time = hour[\"time\"]\n",
    "            hours.append(hour_time)\n",
    "            hour_labels.append(hour_time[-5:]) \n",
    "            tempC.append(hour[\"temp_c\"])\n",
    "            feelslikeC.append(hour[\"feelslike_c\"])\n",
    "            windKph.append(hour[\"wind_kph\"])\n",
    "            gustKph.append(hour[\"gust_kph\"])\n",
    "            precipMm.append(hour[\"precip_mm\"])\n",
    "            snowCm.append(hour.get(\"snow_cm\", 0))\n",
    "            humidity.append(hour[\"humidity\"])\n",
    "            cloud.append(hour[\"cloud\"])\n",
    "            windchillC.append(hour[\"windchill_c\"])\n",
    "            heatindexC.append(hour[\"heatindex_c\"])\n",
    "            dewpointC.append(hour[\"dewpoint_c\"])\n",
    "            rainChance.append(hour[\"chance_of_rain\"])\n",
    "            snowChance.append(hour[\"chance_of_snow\"])\n",
    "            visibilityKm.append(hour[\"vis_km\"])\n",
    "            uvIndex.append(hour[\"uv\"])\n",
    "\n",
    "    def filter_xticks(hours):\n",
    "        xticks = []\n",
    "        xlabels = []\n",
    "        for i, h in enumerate(hours):\n",
    "            hour = int(h[-5:-3])\n",
    "            if hour in [0, 4, 8, 12, 16, 20]:\n",
    "                xticks.append(i)\n",
    "                xlabels.append(h[-5:])\n",
    "        return xticks, xlabels\n",
    "\n",
    "    def plotSubplot(data, titles, i):\n",
    "        plt.subplot(6, 1, i)\n",
    "        for d, t in zip(data, titles):\n",
    "            plt.plot(hours, d, label=t)\n",
    "        xticks, xlabels = filter_xticks(hours)\n",
    "        plt.xticks(xticks, xlabels, rotation=45)\n",
    "        for boundary in dayends:\n",
    "            plt.axvline(x=boundary, color='gray', linestyle='--', alpha=0.5)\n",
    "            di = dayends.index(boundary)\n",
    "            dl = weatherData[\"forecast\"][\"forecastday\"][di][\"date\"]\n",
    "            plt.text(boundary + 1, plt.ylim()[1], dl, rotation=0, ha='left', va='bottom', fontsize=8, color='gray')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.title(' / '.join(titles))\n",
    "\n",
    "    plt.figure(figsize=(16, 24))\n",
    "    plotSubplot([tempC, feelslikeC], [\"Temperature (°C)\", \"Feels Like (°C)\"], 1)\n",
    "    plotSubplot([windKph, gustKph], [\"Wind Speed (kph)\", \"Gust Speed (kph)\"], 2)\n",
    "    plotSubplot([precipMm, snowCm], [\"Precipitation (mm)\", \"Snow (cm)\"], 3)\n",
    "    plotSubplot([humidity, cloud], [\"Humidity (%)\", \"Cloud Cover (%)\"], 4)\n",
    "    plotSubplot([windchillC, heatindexC, dewpointC], [\"Wind Chill (°C)\", \"Heat Index (°C)\", \"Dew Point (°C)\"], 5)\n",
    "    plotSubplot([rainChance, snowChance], [\"Chance of Rain (%)\", \"Chance of Snow (%)\"], 6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 5))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(hours, visibilityKm, 'g-', label=\"Visibility (km)\")\n",
    "    ax2.plot(hours, uvIndex, 'b-', label=\"UV Index\")\n",
    "    xticks, xlabels = filter_xticks(hours)\n",
    "    ax1.set_xticks(xticks)\n",
    "    ax1.set_xticklabels(xlabels, rotation=45)\n",
    "    for boundary in dayends:\n",
    "        ax1.axvline(x=boundary, color='gray', linestyle='--', alpha=0.5)\n",
    "        di = dayends.index(boundary)\n",
    "        dl = weatherData[\"forecast\"][\"forecastday\"][di][\"date\"]\n",
    "        ax1.text(boundary + 1, ax1.get_ylim()[1], dl, rotation=0, ha='left', va='bottom', fontsize=8, color='gray')\n",
    "\n",
    "    ax1.set_xlabel(\"Time\")\n",
    "    ax1.set_ylabel(\"Visibility (km)\", color='g')\n",
    "    ax2.set_ylabel(\"UV Index\", color='b')\n",
    "    plt.title(\"Visibility and UV Index\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf97b65b",
   "metadata": {},
   "source": [
    "Level 1 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "bbdd768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task: None\n",
      "Output: No overview found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output': 'No overview found.',\n",
       " 'images': ['https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQUVLI5rn3cyxOGVyilM_U_aQ7kB9PmEyqNsahXPlApFEj7swXqIh1PQQP3bg&s',\n",
       "  'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSpSAboNGEbRkEyf27o46pThzOJCbCimFtuXzxMwdlIOpq7AvIAG0aElunBww&s',\n",
       "  'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSSBGq92D_1Svbw99n2_DY7zVBFPaCtOhyoB4O_CK6f1DngN-d_jR-9E_1dFg&s',\n",
       "  'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSf4YWORgGwgbSa59_yUV_RWfQ2MRT-nGp4YC_3wq9t1y5kMXQ9icGGmAuJe10&s',\n",
       "  'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRDC2qlyQdUW7J2pbHdr_OjXZMP6N5k2oJKK9lVyf60Ia-Dn_uBfp5m8ee_mQ&s',\n",
       "  'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT_Grur6E7_BPOOhZtQHK0oqjBbxu3iQqhs59JBrlA2zGafu-U4yFBkwHdn7Mg&s',\n",
       "  'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRGILiKNSBE7q-tV0mYn20A8QhZLjzhjwdY8pv-DSmrKJrP6uhFsy6DVynwcDE&s',\n",
       "  'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRb6e8uskWRG3kWb5AGFszic-_GYLJT79NDRzhKifbd27Aredd_Reeg-3Sz6MA&s',\n",
       "  'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRf9H4yAwXBTwlbHPHl_HhJByVWnkcnJJUvyCeTR4DwNsiq1luz2tMghRD-a2o&s',\n",
       "  'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS9qAShdoL4O70iwLWdwTB9SToCDiSNuloKfKtsxp9063bZInE7mk7f3bNgYIQ&s'],\n",
       " 'input': 'What is the current fashion like in Tokyo?'}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def runWeatherMind(user_input):\n",
    "    result = weatherMind.invoke({\"input\": user_input})\n",
    "    print(f\"\\nTask: {result.get('task')}\")\n",
    "    print(f\"Output: {result.get('output')}\")\n",
    "    \n",
    "    if 'weatherData' in result:\n",
    "        plotWeatherGraphs(result['weatherData'])\n",
    "    \n",
    "    return result\n",
    "\n",
    "# runWeatherMind(\"how to not feel suicidal after reading documentation\")\n",
    "# runWeatherMind(\"Can you calculate 94 * 2 + 3? and also 24 /5 and also 2**3\")\n",
    "# runWeatherMind(\"Tell me about quantum computing\")\n",
    "# runWeatherMind(\"What is the weather like in London?\")\n",
    "# runWeatherMind(\"Wzhat is the weather like in New Amsterdam?\")\n",
    "runWeatherMind(\"What is the current fashion like in Tokyo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "73e1b3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task: llm\n",
      "Output: llm\n",
      "The term \"semi riddle\" is not a standard or widely recognized phrase in historical or cultural studies, which makes it a bit challenging to provide a precise historical context. However, I can break down the possible components and offer some insights.\n",
      "\n",
      "### Possible Interpretations:\n",
      "1. **Semi as in Semiramis**:\n",
      "   - **Semiramis** is a legendary figure from ancient Assyrian history. She is often associated with myths and legends, including the founding of various cities and monuments. If \"semi\" refers to Semiramis, the \"riddle\" could be related to the myths and legends surrounding her life and deeds.\n",
      "\n",
      "2. **Semi as in Semiotics**:\n",
      "   - **Semiotics** is the study of signs and symbols and their use or interpretation. If \"semi\" refers to semiotics, the \"riddle\" could be related to the interpretation of symbols and signs in historical contexts, such as ancient texts, artifacts, or cultural practices.\n",
      "\n",
      "3. **Semi as in Semi-Precious**:\n",
      "   - If \"semi\" refers to semi-precious stones or materials, the \"riddle\" could be related to historical trade, craftsmanship, or the cultural significance of such materials in different societies.\n",
      "\n",
      "### Historical Context:\n",
      "- **Mythological Context**:\n",
      "  - In the case of Semiramis, the historical context would involve the ancient Near East, particularly Assyria. Semiramis is often depicted as a powerful and wise queen, and her legends include various riddles and challenges she had to overcome. These stories are part of a broader tradition of mythological narratives that often serve to explain historical events or cultural practices.\n",
      "\n",
      "- **Semiotics in History**:\n",
      "  - The study of semiotics can be applied to historical texts and artifacts to understand the meanings and messages conveyed by ancient cultures. For example, the symbols used in ancient Egyptian hieroglyphics or the iconography in medieval manuscripts can be seen as riddles that historians and archaeologists work to decipher.\n",
      "\n",
      "- **Cultural and Economic Context**:\n",
      "  - If the term refers to semi-precious materials, the historical context could involve the trade routes, such as the Silk Road, where such materials were exchanged. The cultural significance of these materials in different societies, such as their use in religious artifacts or royal regalia, could also be explored.\n",
      "\n",
      "### Conclusion:\n",
      "Without more specific information, it's challenging to provide a precise historical context for the term \"semi riddle.\" However, by considering the possible interpretations of \"semi,\" we can explore various historical and cultural contexts that might be relevant. If you have more details or a specific context in mind, please provide them, and I can offer a more targeted explanation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output': 'llm\\nThe term \"semi riddle\" is not a standard or widely recognized phrase in historical or cultural studies, which makes it a bit challenging to provide a precise historical context. However, I can break down the possible components and offer some insights.\\n\\n### Possible Interpretations:\\n1. **Semi as in Semiramis**:\\n   - **Semiramis** is a legendary figure from ancient Assyrian history. She is often associated with myths and legends, including the founding of various cities and monuments. If \"semi\" refers to Semiramis, the \"riddle\" could be related to the myths and legends surrounding her life and deeds.\\n\\n2. **Semi as in Semiotics**:\\n   - **Semiotics** is the study of signs and symbols and their use or interpretation. If \"semi\" refers to semiotics, the \"riddle\" could be related to the interpretation of symbols and signs in historical contexts, such as ancient texts, artifacts, or cultural practices.\\n\\n3. **Semi as in Semi-Precious**:\\n   - If \"semi\" refers to semi-precious stones or materials, the \"riddle\" could be related to historical trade, craftsmanship, or the cultural significance of such materials in different societies.\\n\\n### Historical Context:\\n- **Mythological Context**:\\n  - In the case of Semiramis, the historical context would involve the ancient Near East, particularly Assyria. Semiramis is often depicted as a powerful and wise queen, and her legends include various riddles and challenges she had to overcome. These stories are part of a broader tradition of mythological narratives that often serve to explain historical events or cultural practices.\\n\\n- **Semiotics in History**:\\n  - The study of semiotics can be applied to historical texts and artifacts to understand the meanings and messages conveyed by ancient cultures. For example, the symbols used in ancient Egyptian hieroglyphics or the iconography in medieval manuscripts can be seen as riddles that historians and archaeologists work to decipher.\\n\\n- **Cultural and Economic Context**:\\n  - If the term refers to semi-precious materials, the historical context could involve the trade routes, such as the Silk Road, where such materials were exchanged. The cultural significance of these materials in different societies, such as their use in religious artifacts or royal regalia, could also be explored.\\n\\n### Conclusion:\\nWithout more specific information, it\\'s challenging to provide a precise historical context for the term \"semi riddle.\" However, by considering the possible interpretations of \"semi,\" we can explore various historical and cultural contexts that might be relevant. If you have more details or a specific context in mind, please provide them, and I can offer a more targeted explanation.',\n",
       " 'task': 'llm',\n",
       " 'location': None,\n",
       " 'input': 'explain the historical context behind the semi riddle last msg?'}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runWeatherMind(\"explain the historical context behind the semi riddle last msg?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
